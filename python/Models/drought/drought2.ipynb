{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6034abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'High': np.int64(0), 'Low': np.int64(1), 'Moderate': np.int64(2)}\n",
      "Class distribution after SMOTE: [1291121 1291121 1291121]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.63      0.52      0.57    213792\n",
      "         Low       0.74      0.70      0.72    322781\n",
      "    Moderate       0.04      0.18      0.06     14787\n",
      "\n",
      "    accuracy                           0.62    551360\n",
      "   macro avg       0.47      0.47      0.45    551360\n",
      "weighted avg       0.68      0.62      0.64    551360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[111717  72191  29884]\n",
      " [ 60134 225348  37299]\n",
      " [  5384   6812   2591]]\n",
      "\n",
      "Sample Probabilities for first 5 test samples:\n",
      "Sample 1: [0.2856576  0.29146287 0.4228795 ]\n",
      "Sample 2: [0.34099838 0.4461195  0.2128821 ]\n",
      "Sample 3: [0.04271686 0.8144609  0.1428223 ]\n",
      "Sample 4: [0.6182695  0.19463164 0.18709888]\n",
      "Sample 5: [0.20935132 0.5989744  0.19167434]\n",
      "\n",
      "Model and LabelEncoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Drought Risk Model Training with XGBClassifier\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "\n",
    "# -------------------------\n",
    "# Load your dataset\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"train_timeseries.csv\")\n",
    "\n",
    "# Drop rows with missing score\n",
    "df = df.dropna(subset=['score'])\n",
    "\n",
    "# -------------------------\n",
    "# Feature selection\n",
    "# -------------------------\n",
    "# Use numeric columns only (exclude 'fips', 'date', 'score')\n",
    "features = [c for c in df.columns if c not in ['fips','date','score']]\n",
    "X = df[features]\n",
    "\n",
    "# -------------------------\n",
    "# Create categorical labels from 'score'\n",
    "# -------------------------\n",
    "# Assuming score is 0..1 normalized\n",
    "y_raw = pd.cut(df['score'], bins=[-np.inf, 0.33, 0.66, np.inf], labels=['Low', 'Moderate', 'High'])\n",
    "\n",
    "# Encode labels to integers for XGBClassifier\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)  # Low=0, Moderate=1, High=2 (mapping may vary)\n",
    "\n",
    "print(\"Class mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# -------------------------\n",
    "# Train/test split (stratified)\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Handle class imbalance using SMOTE\n",
    "# -------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", np.bincount(y_train_res))\n",
    "\n",
    "# -------------------------\n",
    "# Initialize XGBClassifier\n",
    "# -------------------------\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# -------------------------\n",
    "# Predictions & Probabilities\n",
    "# -------------------------\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)  # Real probabilities per class\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation\n",
    "# -------------------------\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Sample probabilities\n",
    "print(\"\\nSample Probabilities for first 5 test samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}: {y_proba[i]}\")\n",
    "\n",
    "# -------------------------\n",
    "# Save model and LabelEncoder\n",
    "# -------------------------\n",
    "with open(\"drought_model_xgb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"\\nModel and LabelEncoder saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8254870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12264\\1424529046.py:86: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  today = datetime.utcnow().date()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sri Lanka ===\n",
      "No weather data available.\n",
      "\n",
      "=== India ===\n",
      "No weather data available.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "# -------------------------\n",
    "# Load trained model & label encoder\n",
    "# -------------------------\n",
    "with open(\"drought_model_xgb.pkl\", \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "# -------------------------\n",
    "# Example countries with lat/lon\n",
    "# -------------------------\n",
    "COUNTRY_COORDS = {\n",
    "    \"Sri Lanka\": (7.8731, 80.7718),\n",
    "    \"India\": (20.5937, 78.9629)\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Weather API helpers (Open-Meteo)\n",
    "# -------------------------\n",
    "DAILY_VARS = \"precipitation_sum,temperature_2m_mean,et0_fao_evapotranspiration\"\n",
    "\n",
    "def _safe_get(d, *keys, default=None):\n",
    "    cur = d\n",
    "    for k in keys:\n",
    "        if k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "def fetch_daily_timeseries(lat, lon, start_date, end_date):\n",
    "    \"\"\"Fetch daily weather data for given coordinates and date range.\"\"\"\n",
    "    frames = []\n",
    "\n",
    "    # Past data (archive API)\n",
    "    url = (\n",
    "        f\"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&daily={DAILY_VARS}&timezone=auto\"\n",
    "    )\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        times = _safe_get(data, \"daily\", \"time\", [])\n",
    "        prcp = _safe_get(data, \"daily\", \"precipitation_sum\", [])\n",
    "        tmean = _safe_get(data, \"daily\", \"temperature_2m_mean\", [])\n",
    "        et0 = _safe_get(data, \"daily\", \"et0_fao_evapotranspiration\", [])\n",
    "\n",
    "        if times and len(times) == len(prcp) == len(tmean) == len(et0):\n",
    "            df = pd.DataFrame({\n",
    "                \"date\": pd.to_datetime(times),\n",
    "                \"precipitation_sum\": prcp,\n",
    "                \"temperature_2m_mean\": tmean,\n",
    "                \"et0_fao_evapotranspiration\": et0\n",
    "            })\n",
    "            frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return pd.DataFrame()  # empty\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# Feature engineering\n",
    "# -------------------------\n",
    "def compute_features(df):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    df[\"RainfallLast30Days\"] = df[\"precipitation_sum\"].rolling(30, min_periods=1).sum()\n",
    "    df[\"TemperatureAvg7\"] = df[\"temperature_2m_mean\"].rolling(7, min_periods=1).mean()\n",
    "    df[\"ET0Last30Days\"] = df[\"et0_fao_evapotranspiration\"].rolling(30, min_periods=1).sum()\n",
    "    return df[[\"date\", \"RainfallLast30Days\", \"TemperatureAvg7\", \"ET0Last30Days\"]]\n",
    "\n",
    "# -------------------------\n",
    "# Prediction for two countries\n",
    "# -------------------------\n",
    "today = datetime.utcnow().date()\n",
    "start_date = (today - timedelta(days=60)).isoformat()\n",
    "end_date = today.isoformat()\n",
    "\n",
    "for country, (lat, lon) in COUNTRY_COORDS.items():\n",
    "    print(f\"\\n=== {country} ===\")\n",
    "    df_weather = fetch_daily_timeseries(lat, lon, start_date, end_date)\n",
    "    if df_weather.empty:\n",
    "        print(\"No weather data available.\")\n",
    "        continue\n",
    "\n",
    "    feats = compute_features(df_weather)\n",
    "    X_pred = feats.drop(columns=[\"date\"])\n",
    "\n",
    "    # Predict probabilities\n",
    "    probs = clf.predict_proba(X_pred)\n",
    "    last_probs = probs[-1]  # latest day\n",
    "\n",
    "    # Map to class labels\n",
    "    class_probs = dict(zip(le.classes_, last_probs))\n",
    "    print(\"Probabilities for today:\")\n",
    "    for k, v in class_probs.items():\n",
    "        print(f\"  {k}: {v:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab2878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {'latitude': 7.838313, 'longitude': 80.79284, 'generationtime_ms': 3.256678581237793, 'utc_offset_seconds': 19800, 'timezone': 'Asia/Colombo', 'timezone_abbreviation': 'GMT+5:30', 'elevation': 232.0, 'daily_units': {'time': 'iso8601', 'precipitation_sum': 'mm', 'temperature_2m_mean': '°C', 'et0_fao_evapotranspiration': 'mm'}, 'daily': {'time': ['2025-07-01', '2025-07-02', '2025-07-03', '2025-07-04', '2025-07-05', '2025-07-06', '2025-07-07', '2025-07-08', '2025-07-09', '2025-07-10', '2025-07-11', '2025-07-12', '2025-07-13', '2025-07-14', '2025-07-15', '2025-07-16', '2025-07-17', '2025-07-18', '2025-07-19', '2025-07-20', '2025-07-21', '2025-07-22', '2025-07-23', '2025-07-24', '2025-07-25', '2025-07-26', '2025-07-27', '2025-07-28', '2025-07-29', '2025-07-30', '2025-07-31', '2025-08-01', '2025-08-02', '2025-08-03', '2025-08-04', '2025-08-05', '2025-08-06', '2025-08-07', '2025-08-08', '2025-08-09', '2025-08-10', '2025-08-11', '2025-08-12', '2025-08-13', '2025-08-14', '2025-08-15', '2025-08-16', '2025-08-17', '2025-08-18', '2025-08-19', '2025-08-20', '2025-08-21', '2025-08-22', '2025-08-23', '2025-08-24', '2025-08-25', '2025-08-26'], 'precipitation_sum': [0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.4, 1.4, 1.2, 0.0, 0.7, 0.0, 0.5, 0.4, 0.8, 1.9, 3.2, 0.7, 3.1, 2.7, 3.0, 0.2, 3.2, 1.3, 0.6, 0.8, 1.1, 0.0, 4.0, 0.9, 3.6, 2.0, 0.8, 0.0, 1.2, 1.3, 0.3, 0.1, 0.4, 0.7, 3.7, 0.7, 0.7, 0.5, 1.0, 0.6, 0.0, 0.0, 1.4, 7.8, 1.3, 0.0, None, None], 'temperature_2m_mean': [27.9, 27.9, 28.1, 28.5, 28.5, 27.6, 28.3, 28.3, 28.5, 28.7, 28.1, 27.6, 28.1, 27.1, 27.6, 27.1, 27.2, 26.7, 26.7, 25.2, 25.4, 25.1, 25.5, 25.4, 26.6, 25.8, 27.1, 28.0, 28.4, 28.6, 27.8, 27.4, 26.9, 25.3, 27.0, 26.5, 27.4, 27.5, 27.4, 27.5, 27.8, 27.0, 26.2, 26.1, 26.9, 26.6, 26.7, 26.2, 26.9, 28.0, 28.7, 29.1, 27.8, 27.5, 28.4, None, None], 'et0_fao_evapotranspiration': [6.45, 6.36, 6.2, 6.87, 6.62, 5.91, 6.6, 6.58, 6.36, 6.03, 6.23, 5.89, 6.61, 5.53, 6.2, 5.58, 5.54, 4.81, 5.25, 3.54, 3.61, 3.04, 4.05, 4.22, 5.34, 4.43, 6.03, 6.39, 6.51, 6.05, 5.88, 4.78, 4.7, 3.0, 5.54, 5.01, 6.18, 5.96, 5.78, 5.68, 6.53, 6.16, 5.36, 5.04, 6.2, 6.08, 5.67, 4.47, 6.1, 7.35, 6.74, 6.18, 5.59, 5.95, 7.02, None, None]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "lat, lon = 7.8731, 80.7718  # Sri Lanka\n",
    "url = f\"https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={lon}&start_date=2025-07-01&end_date=2025-08-26&daily=precipitation_sum,temperature_2m_mean,et0_fao_evapotranspiration&timezone=auto\"\n",
    "r = requests.get(url)\n",
    "print(r.status_code, r.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    r = requests.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    print(data.keys())  # debug output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
